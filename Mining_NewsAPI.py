# -*- coding: utf-8 -*-
"""Mining-NewsAPI

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vqCQrGVwclOsPnesMc0rErzvz4dovO9E

## **Install Package yang Dibutuhkan**
"""

# !pip install newsapi-python

# !pip install Sastrawi

# !pip install newspaper3k

# !pip install wordcloud

"""## **Import Library yang Dibutuhkan**"""

import pandas as pd
import json
import datetime
import pprint
import requests
from newsapi.newsapi_client import NewsApiClient
from textblob import TextBlob
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# API 
secret = "12fd31f62amshe0539f78a152f87p11c739jsn89c9f491b99e"

# Definisikan endpoint yang akan digunakan untuk mengakses google news
url = 'https://google-news.p.rapidapi.com/v1/search'

# Definisikan atribut di dalam parameters
parameters = {
	'q': input('Masukkan keyword yang diinginkan : '), 
  'country': 'ID', 
  'lang': 'id',
	#'pageSize': 100, # maximum is 100
	#'apiKey': secret # your own API key
}

# Definiskan headers yang akan di proses dalam API
headers= {
    'X-RapidAPI-Key': secret,
    'X-RapidAPI-Host': 'google-news.p.rapidapi.com'
  }

# Make the request
response = requests.get(url,
						params = parameters, headers=headers)

# Convert the response to
# JSON format and pretty print it
response_json = response.json()
pprint.pprint(response_json)

from wordcloud import WordCloud
import matplotlib.pyplot as plt


text_combined = ''

for i in response_json['articles']:
	
	if i['title'] != None:
		text_combined += i['title'] + ' '
		
wordcount={}
for word in text_combined.split():
	if word not in wordcount:
		wordcount[word] = 1
	else:
		wordcount[word] += 1

for k,v, in sorted(wordcount.items(),
				key=lambda words: words[1],
				reverse = True):
	print(k,v)

# initializing bad_chars_list
f = open("stop words.txt", "r")
stopword_list = []
for line in f:
    stripped_line = line.strip()
    line_list = stripped_line.split()
    stopword_list.append(line_list[0])
f.close()

len(stopword_list)

r = text_combined.replace('\s+',
						' ').replace(',',
									' ').replace('.',
													' ')
words = r.split()
rst = [word for word in words if
	( word.lower() not in stopword_list
		and len(word) > 3) ]

rst = ' '.join(rst)

wordcount={}

for word in rst.split():
	
	if word not in wordcount:
		wordcount[word] = 1
	else:
		wordcount[word] += 1

for k,v, in sorted(wordcount.items(),
				key=lambda words: words[1],
				reverse = True):
	print(k,v)

word = WordCloud(min_font_size = 10, width = 800, height = 800,
                background_color ='white').generate(rst)
#plt.figure()
# plot the WordCloud image                      
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(word, interpolation ="bilinear")
plt.axis("off")
plt.tight_layout(pad = 0)
 
plt.show()